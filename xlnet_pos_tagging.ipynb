{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "xlnet_pos_tagging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96c498a6a7184efa8b356f3be26d9cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c9242e4128f348a8b6b4b3332f395528",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f06c1fdbd4ca453fac4fa302b757e505",
              "IPY_MODEL_32b8be9d18ef4c0897b04f8bb27e4a08"
            ]
          }
        },
        "c9242e4128f348a8b6b4b3332f395528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f06c1fdbd4ca453fac4fa302b757e505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9460da19f66f408380a3f5cb488d3316",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 798011,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 798011,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e178df9c16544a1890751f4aa40fd70f"
          }
        },
        "32b8be9d18ef4c0897b04f8bb27e4a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_868e1b7f782044a2a1ee40bb0bb05126",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 798k/798k [00:00&lt;00:00, 6.26MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db669459903b4992bb0e1afe9bfb31bc"
          }
        },
        "9460da19f66f408380a3f5cb488d3316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e178df9c16544a1890751f4aa40fd70f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "868e1b7f782044a2a1ee40bb0bb05126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db669459903b4992bb0e1afe9bfb31bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31c9fc4599b3407698f365007bec811c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d01b7aa10532433ca59ceb77f1d73536",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4e8aa7f0de1e4f9f8acdfb0fc8a3f837",
              "IPY_MODEL_5b38607583144df184a86baf78a6a2e6"
            ]
          }
        },
        "d01b7aa10532433ca59ceb77f1d73536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e8aa7f0de1e4f9f8acdfb0fc8a3f837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_802347c7cd0c4a42875acc9b7a7a8f13",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1382015,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1382015,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b7b3c2d995b4221b6670e71baf03e08"
          }
        },
        "5b38607583144df184a86baf78a6a2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_74f32b6cf4244794b5c5658957db9381",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.38M/1.38M [00:00&lt;00:00, 5.15MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5517173d098046b08bfe364915cb2c30"
          }
        },
        "802347c7cd0c4a42875acc9b7a7a8f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b7b3c2d995b4221b6670e71baf03e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74f32b6cf4244794b5c5658957db9381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5517173d098046b08bfe364915cb2c30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narhim/nn_project/blob/master/xlnet_pos_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYXoCQVoohY0",
        "outputId": "cbacd253-9ef2-4b97-8a25-7285c713294f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k7l_1W_7uKv4",
        "outputId": "d79c0d6f-62d5-4355-c764-077bf0bbffbe"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iYnHwiGS_JG"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "AyxZH1XcuM0e",
        "outputId": "bac52186-4209-4f42-f90e-ea791f473c02"
      },
      "source": [
        "%cd /content/drive/MyDrive/NN_groupWS2021/final_project/\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1JjKm5t8lyp2F4kr-Bq8HIArzsrnahAhe/NN_groupWS2021/final_project\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1JjKm5t8lyp2F4kr-Bq8HIArzsrnahAhe/NN_groupWS2021/final_project'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkDh5yvs7oyh"
      },
      "source": [
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmYWXg8S3A5K"
      },
      "source": [
        "sent_word_ids = []\n",
        "sents = []\n",
        "sents_pos = []\n",
        "num_sents = 0\n",
        "with open('sample.tsv') as file:\n",
        "    #tsv_file = csv.reader(file, delimiter=\"\\t\", quotechar='\"')\n",
        "    word_ids = []\n",
        "    words = []\n",
        "    pos = []\n",
        "    for line in file:\n",
        "        try:\n",
        "            id, word, tag = line.rstrip('\\n').split('\\t')\n",
        "        except ValueError:\n",
        "            # this will happen when you get to the line where there's only the '*' token\n",
        "            num_sents += 1\n",
        "            # reach the * line\n",
        "            id = line.rstrip('\\n').split()[0]\n",
        "        if id == '*':\n",
        "            assert len(word_ids) == len(words) == len(pos)\n",
        "            #print(word_ids)\n",
        "            #print(words)\n",
        "            #print(pos)\n",
        "            sent_word_ids.append(word_ids)\n",
        "            sents.append(words)\n",
        "            sents_pos.append(pos)\n",
        "            word_ids = []\n",
        "            words = []\n",
        "            pos = []\n",
        "        else:\n",
        "            word_ids.append(int(id))\n",
        "            words.append(word)\n",
        "            pos.append(tag)\n",
        "assert len(sent_word_ids) == len(sents) == len(sents_pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_WWjEFXxCWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40613fa4-6398-4f24-a432-c82c089f5aa3"
      },
      "source": [
        "cnt = 0\n",
        "for w_idx, s, t in zip(sent_word_ids, sents, sents_pos):\n",
        "    print(w_idx,'\\n', s, '\\n', t, '\\n')\n",
        "    cnt += 1\n",
        "    if cnt > 10:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] \n",
            " ['A', 'Saudi', 'woman', 'issues', 'a', 'voice', 'recording', 'in', 'which', 'she', 'mourns', 'her', 'brother', 'and', 'demands', 'the', 'punishment', 'of', 'his', 'killers', '.'] \n",
            " ['DT', 'JJ', 'NN', 'VBZ', 'DT', 'NN', 'NN', 'IN', 'WDT', 'PRP', 'VBZ', 'PRP$', 'NN', 'CC', 'VBZ', 'DT', 'NN', 'IN', 'PRP$', 'NNS', '.'] \n",
            "\n",
            "[0] \n",
            " ['HAD1999'] \n",
            " ['NNP'] \n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56] \n",
            " ['In', 'a', 'unique', 'way', ',', 'a', 'young', 'Saudi', 'woman', 'has', 'resorted', 'to', 'issuing', 'a', 'sound', 'tape', 'in', 'which', 'she', 'mourns', 'her', 'brother', 'murdered', 'in', 'Hafr', 'Al', 'Batin', ',', 'in', 'the', 'hope', 'of', 'rekindling', 'interest', 'in', 'his', 'case', ',', 'in', 'which', '3', 'young', 'men', 'were', 'accused', 'of', 'killing', 'him', 'and', 'which', 'has', 'not', 'so', 'far', 'been', 'resolved', '.'] \n",
            " ['IN', 'DT', 'JJ', 'NN', ',', 'DT', 'JJ', 'JJ', 'NN', 'VBZ', 'VBN', 'IN', 'VBG', 'DT', 'NN', 'NN', 'IN', 'WDT', 'PRP', 'VBZ', 'PRP$', 'NN', 'VBN', 'IN', 'NNP', 'NNP', 'NNP', ',', 'IN', 'DT', 'NN', 'IN', 'VBG', 'NN', 'IN', 'PRP$', 'NN', ',', 'IN', 'WDT', 'CD', 'JJ', 'NNS', 'VBD', 'VBN', 'IN', 'VBG', 'PRP', 'CC', 'WDT', 'VBZ', 'RB', 'RB', 'RB', 'VBN', 'VBN', '.'] \n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43] \n",
            " ['The', 'tape', 'contains', 'excerpts', 'of', 'poetry', ',', 'dramatic', 'voice', 'recitals', ',', 'detailed', 'accounts', 'of', 'the', 'young', 'man', \"'s\", 'murder', 'circumstances', 'of', 'the', 'background', 'to', 'the', 'investigation', 'of', 'the', 'case', 'for', 'which', 'the', 'young', 'woman', 'is', 'demanding', 'expedited', 'proceedings', 'and', 'punishment', 'of', 'those', 'involved', '.'] \n",
            " ['DT', 'NN', 'VBZ', 'NNS', 'IN', 'NN', ',', 'JJ', 'NN', 'NNS', ',', 'JJ', 'NNS', 'IN', 'DT', 'JJ', 'NN', 'POS', 'NN', 'NNS', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'WDT', 'DT', 'JJ', 'NN', 'VBZ', 'VBG', 'VBN', 'NNS', 'CC', 'NN', 'IN', 'DT', 'VBN', '.'] \n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43] \n",
            " ['The', 'details', 'of', 'the', 'case', 'go', 'back', '4', 'years', 'to', 'the', 'time', 'when', 'the', 'girl', \"'s\", 'brother', ',', 'Abdullah', 'Khaled', 'al', '-', 'Harbi', '-LRB-', '18', 'years', 'old', '-RRB-', ',', 'and', 'his', 'friend', 'were', 'murdered', 'on', 'the', 'first', 'day', 'of', 'Eidul', 'Adha', '1423', 'H', '.'] \n",
            " ['DT', 'NNS', 'IN', 'DT', 'NN', 'VBP', 'RB', 'CD', 'NNS', 'IN', 'DT', 'NN', 'WRB', 'DT', 'NN', 'POS', 'NN', ',', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', '-LRB-', 'CD', 'NNS', 'JJ', '-RRB-', ',', 'CC', 'PRP$', 'NN', 'VBD', 'VBN', 'IN', 'DT', 'JJ', 'NN', 'IN', 'NNP', 'NNP', 'CD', 'NNP', '.'] \n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] \n",
            " ['3', 'young', 'men', 'were', 'accused', 'of', 'killing', 'both', ',', 'and', 'were', 'investigated', '.'] \n",
            " ['CD', 'JJ', 'NNS', 'VBD', 'VBN', 'IN', 'VBG', 'DT', ',', 'CC', 'VBD', 'VBN', '.'] \n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42] \n",
            " ['Incriminating', 'evidence', 'was', 'found', 'despite', 'denials', 'by', 'two', 'of', 'them', 'and', 'a', 'confession', 'to', 'the', 'crime', 'by', 'the', 'third', ',', 'according', 'to', 'the', 'report', 'prepared', 'by', 'colleague', 'Safr', 'Al', '-', 'Azman', 'and', 'published', 'by', 'the', 'Saudi', 'paper', '\"', 'Al', '-', 'watan', '\"', '.'] \n",
            " ['VBG', 'NN', 'VBD', 'VBN', 'IN', 'NNS', 'IN', 'CD', 'IN', 'PRP', 'CC', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'JJ', ',', 'VBG', 'IN', 'DT', 'NN', 'VBN', 'IN', 'NN', 'NNP', 'NNP', 'HYPH', 'NNP', 'CC', 'VBN', 'IN', 'DT', 'JJ', 'NN', '``', 'NNP', 'HYPH', 'NNP', \"''\", '.'] \n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29] \n",
            " ['The', 'girl', 'said', 'that', 'the', 'idea', 'of', 'the', 'tape', 'was', 'born', 'following', 'failure', 'to', 'obtain', 'response', 'to', 'her', 'demands', 'that', 'the', 'investigation', 'proceedings', 'be', 'expedited', 'and', 'the', 'accused', 'tried', '.'] \n",
            " ['DT', 'NN', 'VBD', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'VBD', 'VBN', 'VBG', 'NN', 'TO', 'VB', 'NN', 'IN', 'PRP$', 'NNS', 'IN', 'DT', 'NN', 'NNS', 'VB', 'VBN', 'CC', 'DT', 'VBN', 'VBN', '.'] \n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18] \n",
            " ['She', 'indicated', 'that', 'she', 'had', 'been', 'working', 'on', 'the', 'tape', 'for', 'about', 'a', 'year', ',', 'writing', 'its', 'poems', '.'] \n",
            " ['PRP', 'VBD', 'IN', 'PRP', 'VBD', 'VBN', 'VBG', 'IN', 'DT', 'NN', 'IN', 'RB', 'DT', 'NN', ',', 'VBG', 'PRP$', 'NNS', '.'] \n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26] \n",
            " ['She', 'also', 'wrote', 'stories', 'based', 'on', 'the', 'incident', 'and', 'backed', 'them', 'up', 'with', 'religious', 'hymns', ',', 'chosing', '\"', 'A', 'Cry', 'of', 'Pain', '\"', 'as', 'its', 'title', '.'] \n",
            " ['PRP', 'RB', 'VBD', 'NNS', 'VBN', 'IN', 'DT', 'NN', 'CC', 'VBD', 'PRP', 'RP', 'IN', 'JJ', 'NNS', ',', 'VBG', '``', 'DT', 'NNP', 'IN', 'NNP', \"''\", 'IN', 'PRP$', 'NN', '.'] \n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] \n",
            " ['For', 'his', 'part', ',', 'an', 'unnamed', 'source', 'from', 'the', 'Public', 'Investigation', 'and', 'Prosecutor', \"'s\", 'Board', 'in', 'the', 'Eastern', 'Province', 'explained', 'that', 'the', 'case', 'in', 'question', 'had', 'been', 'brought', 'before', 'the', 'authorities', 'concerned', 'after', 'it', 'was', 'returned', 'from', 'the', 'Hafr', 'Al', 'Batin', 'Court', ',', 'indicating', 'that', 'the', 'case', 'had', 'the', 'attention', 'of', 'both', 'the', 'Prince', 'of', 'the', 'Eastern', 'Province', 'and', 'his', 'deputy', 'and', 'that', 'they', 'were', 'following', 'up', 'on', 'it', '.'] \n",
            " ['IN', 'PRP$', 'NN', ',', 'DT', 'JJ', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'CC', 'NNP', 'POS', 'NNP', 'IN', 'DT', 'NNP', 'NNP', 'VBD', 'IN', 'DT', 'NN', 'IN', 'NN', 'VBD', 'VBN', 'VBN', 'IN', 'DT', 'NNS', 'VBN', 'IN', 'PRP', 'VBD', 'VBN', 'IN', 'DT', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'VBG', 'IN', 'DT', 'NN', 'VBD', 'DT', 'NN', 'IN', 'CC', 'DT', 'NNP', 'IN', 'DT', 'NNP', 'NNP', 'CC', 'PRP$', 'NN', 'CC', 'IN', 'PRP', 'VBD', 'VBG', 'RP', 'IN', 'PRP', '.'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJna0GgaXK4C"
      },
      "source": [
        "## 80/10/10 train, val, test splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soF3t4YxOdcB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_tags, val_tags = train_test_split(sents, sents_pos, test_size=.2, random_state=42)\n",
        "val_texts, test_texts, val_tags, test_tags = train_test_split(val_texts, val_tags, test_size=.5, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X68M4MJUUtUD"
      },
      "source": [
        "#Toy samples for faster development\n",
        "#top = int(0.01*len(sents))\n",
        "#sents = sents[0:top]\n",
        "#sents_pos = sents_pos[0:top]\n",
        "#train_texts, val_texts, train_tags, val_tags = train_test_split(sents, sents_pos, test_size=.2, random_state=42)\n",
        "#val_texts, test_texts, val_tags, test_tags = train_test_split(val_texts, val_tags, test_size=.5, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLCuLMNYmHTL"
      },
      "source": [
        "## create encodings for our tokens and tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbS06POuXI67"
      },
      "source": [
        "unique_tags = set(tag for doc in sents_pos for tag in doc)\n",
        "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
        "id2tag = {id: tag for tag, id in tag2id.items()}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqsmGl8AnD3G"
      },
      "source": [
        "## install transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "farPrR4WnFQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0c29e5-f006-4f6d-b1d3-edbe77846f40"
      },
      "source": [
        "%pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\r\u001b[K     |▏                               | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 29.6MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 23.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 21.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 22.4MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 16.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 16.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 81kB 17.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92kB 15.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 102kB 16.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 112kB 16.9MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 16.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 133kB 16.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 143kB 16.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 153kB 16.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 163kB 16.9MB/s eta 0:00:01\r\u001b[K     |██▉                             | 174kB 16.9MB/s eta 0:00:01\r\u001b[K     |███                             | 184kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 194kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 204kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 215kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 225kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 235kB 16.9MB/s eta 0:00:01\r\u001b[K     |████                            | 245kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 256kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 266kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 276kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 286kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 296kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 307kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 317kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 327kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 337kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 348kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 358kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 368kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 378kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 389kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 399kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 409kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 419kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 430kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 440kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 450kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 460kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 471kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 481kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 491kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 501kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 512kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 522kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 532kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 542kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 552kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 563kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 573kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 583kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 593kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 604kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 614kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 624kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 634kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 645kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 655kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 665kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 675kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 686kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 696kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 706kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 716kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 727kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 737kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 747kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 757kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 768kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 778kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 788kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 798kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 808kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 819kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 829kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 839kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 849kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 860kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 870kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 880kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 890kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 901kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 911kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 921kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 931kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 942kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 952kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 962kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 972kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 983kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 993kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.0MB 16.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 56.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=44faabbe3e966c475ece5d071de98bfcefa5f16b5501a40a4859835e39d7ab05\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwjYGhxTnPDI"
      },
      "source": [
        "## token encodings for train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxlbgmwESyWP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "96c498a6a7184efa8b356f3be26d9cea",
            "c9242e4128f348a8b6b4b3332f395528",
            "f06c1fdbd4ca453fac4fa302b757e505",
            "32b8be9d18ef4c0897b04f8bb27e4a08",
            "9460da19f66f408380a3f5cb488d3316",
            "e178df9c16544a1890751f4aa40fd70f",
            "868e1b7f782044a2a1ee40bb0bb05126",
            "db669459903b4992bb0e1afe9bfb31bc",
            "31c9fc4599b3407698f365007bec811c",
            "d01b7aa10532433ca59ceb77f1d73536",
            "4e8aa7f0de1e4f9f8acdfb0fc8a3f837",
            "5b38607583144df184a86baf78a6a2e6",
            "802347c7cd0c4a42875acc9b7a7a8f13",
            "9b7b3c2d995b4221b6670e71baf03e08",
            "74f32b6cf4244794b5c5658957db9381",
            "5517173d098046b08bfe364915cb2c30"
          ]
        },
        "outputId": "57156f7f-9f49-48c7-cccc-01f8d9b3ae9a"
      },
      "source": [
        "#Bert\n",
        "from transformers import XLNetTokenizerFast\n",
        "tokenizer = XLNetTokenizerFast.from_pretrained('xlnet-base-cased')\n",
        "train_encodings = tokenizer(train_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "val_encodings = tokenizer(val_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "test_encodings = tokenizer(test_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96c498a6a7184efa8b356f3be26d9cea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31c9fc4599b3407698f365007bec811c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1382015.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1H253OMoNkS"
      },
      "source": [
        "Bert and many models like it use a method called WordPiece\n",
        "Tokenization, meaning that single words are split into multiple tokens such that each token is likely to be in the\n",
        "vocabulary. For example, DistilBert's tokenizer would split the Twitter handle `@huggingface` into the tokens `['@',\n",
        "'hugging', '##face']`. This is a problem for us because we have exactly one tag per token. If the tokenizer splits a\n",
        "token into multiple sub-tokens, then we will end up with a mismatch between our tokens and our labels.\n",
        "\n",
        "One way to handle this is to only train on the tag labels for the first subtoken of a split token. We can do this in\n",
        "Transformers by setting the labels we wish to ignore to `-100`. In the example above, if the label for\n",
        "`@HuggingFace` is `3` (indexing `B-corporation`), we would set the labels of `['@', 'hugging', '##face']` to\n",
        "`[3, -100, -100]`.\n",
        "\n",
        "For each sub-token returned by the tokenizer, the offset mapping gives us a tuple indicating the sub-token's\n",
        "start position and end position relative to the original token it was split from. That means that if the first position\n",
        "in the tuple is anything other than `0`, we will set its corresponding label to `-100`. While we're at it, we can\n",
        "also set labels to `-100` if the second position of the offset mapping is `0`, since this means it must be a\n",
        "special token like `[PAD]` or `[CLS]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N-fUhubobzJ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def encode_tags(tags, encodings):\n",
        "    labels = [[tag2id[tag] for tag in doc] for doc in tags]\n",
        "    encoded_labels = []\n",
        "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
        "        # create an empty array of -100\n",
        "        doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
        "        arr_offset = np.array(doc_offset)\n",
        "\n",
        "        # set labels whose first offset position is 0 and the second is not 0\n",
        "        doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
        "        encoded_labels.append(doc_enc_labels.tolist())\n",
        "\n",
        "    return encoded_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLnNrBI9Txzk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "546dc517-aa3d-48be-d3ce-e090dbec291f"
      },
      "source": [
        "train_labels = encode_tags(train_tags, train_encodings)\n",
        "val_labels = encode_tags(val_tags, val_encodings)\n",
        "test_labels = encode_tags(test_tags, test_encodings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-1bc01f56f4ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_encodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_encodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_encodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-f0fddf73844f>\u001b[0m in \u001b[0;36mencode_tags\u001b[0;34m(tags, encodings)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# set labels whose first offset position is 0 and the second is not 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdoc_enc_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marr_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mencoded_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_enc_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: NumPy boolean array indexing assignment cannot assign 21 input values to the 24 output values where the mask is true"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPSupAxFpO7Q"
      },
      "source": [
        "## create a dataset object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thOTr5r5pQ-a"
      },
      "source": [
        "import torch\n",
        "\n",
        "class OntonetesDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uzFPwN1fMhS"
      },
      "source": [
        "#try:\n",
        "train_encodings.pop(\"offset_mapping\") # we don't want to pass this to the model\n",
        "val_encodings.pop(\"offset_mapping\")\n",
        "test_encodings.pop(\"offset_mapping\")\n",
        "#except:\n",
        "#  pass  \n",
        "train_dataset = OntonetesDataset(xlnet_train_encodings, xlnet_train_labels)\n",
        "val_dataset = OntonetesDataset(xlnet_val_encodings, xlnet_val_labels)\n",
        "test_dataset = OntonetesDataset(xlnet_test_encodings, xlnet_test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiWzb163s0p6"
      },
      "source": [
        "## check the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRv5dKuas24K"
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X6qsiuws6iu"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0IE8Q_VtSvQ"
      },
      "source": [
        "## Load model for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g7ajPMwtU8p"
      },
      "source": [
        "from transformers import XLNetBertForTokenClassification\n",
        "model = XLNetForTokenClassification.from_pretrained('xlnet-base-cased', num_labels=len(unique_tags))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGB6A1jx-RyG"
      },
      "source": [
        "##Install wandb to keep track of training\n",
        "User: narhim\n",
        "Password: 123579trms121092\n",
        "(Delete before submitting)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Dus9o5x-ZSS"
      },
      "source": [
        "%pip install wandb\n",
        "import wandb\n",
        "wandb.login()\n",
        "%env WANDB_PROJECT = nn_project_xlnet\n",
        "%env WANDB_LOG_MODEL = true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-kNpNXc952a"
      },
      "source": [
        "##Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fj3mvB7EySt"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.multioutput import MultiOutputClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx12hQydhRI3"
      },
      "source": [
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DistilBertForSequenceClassification, AdamW\n",
        "\n",
        "#Send to CUDA\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "#train_loader = DataLoader(train_dataset, batch_size_train, shuffle=True)\n",
        "#val_loader = DataLoader(val_dataset, batch_size_val, shuffle=True)\n",
        "#optim = AdamW(model.parameters(), lr=5e-5)\n",
        "#\n",
        "#for epoch in range(1, n_epochs + 1):\n",
        "#    train(optim,train_loader,model,epoch)\n",
        "#    val(val_loader,model,epoch)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKAaRHBeQr4K"
      },
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "#model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total # of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset            # evaluation dataset\n",
        ")\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYtN5oHGqJHE"
      },
      "source": [
        "#Save model\n",
        "trainer.save_model()\n",
        "#Make predictions\n",
        "predictions, label_ids, metrics = trainer.predict(val_dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax-R7bAt9Y8n"
      },
      "source": [
        "##Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKp9NtOgSpbu"
      },
      "source": [
        "#Evaluation functions\n",
        "#Evaluation functions\n",
        "def evaluate(model, test_loader):\n",
        "  model.eval()\n",
        "  eval_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for batch in eval_loader:\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "      tokens = batch['token_type_ids'].to(device)\n",
        "      outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "      eval_loss = outputs[0]\n",
        "      print(eval_loss)\n",
        "      preds = outputs[1].argmax(2, keepdim=False)\n",
        "      for t in tokens:\n",
        "        label_words=bert_tokenizer.convert_ids_to_tokens(t)\n",
        "        print(label_words)\n",
        "        #if l != \"logits\" and l!=loss:\n",
        "        #  for g in l:\n",
        "        #    label_words=bert_tokenizer.convert_ids_to_tokens(g)\n",
        "        #    print(label_words)\n",
        "      print(\"These are the preds\")\n",
        "      #print(preds)\n",
        "      #for p in preds:\n",
        "      #  predicted_token = bert_tokenizer.convert_ids_to_tokens(p)\n",
        "      #  print(\"These are the words\")\n",
        "      #  print(predicted_token)\n",
        "      #print(\"these are the labels\")\n",
        "      #for l in labels:\n",
        "      #  label_words=bert_tokenizer.convert_ids_to_tokens(l)\n",
        "      #  print(label_words)\n",
        "      #print(labels.shape)\n",
        "      #print(model.decode(labels))\n",
        "      #labels.reshape(1)\n",
        "      #preds.reshape(preds.shape[0])\n",
        "      #BUG: CALCULATING SCORES, MULTICLASS\n",
        "      #precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "      #acc = accuracy_score(labels, preds)\n",
        "      #correct += preds.eq(labels.view_as(preds)).sum()\n",
        "      \n",
        "    \n",
        "  eval_loss /= len(eval_loader.dataset)\n",
        "  eval_losses.append(eval_loss)\n",
        "  print('\\nEvaluation set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    eval_loss, correct, len(eval_loader.dataset),\n",
        "    100. * correct / len(eval_loader.dataset)))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4DpFZ5G9vh-"
      },
      "source": [
        "#Make predictions\n",
        "#eval_losses = []\n",
        "#model.eval()\n",
        "#eval_loader = DataLoader(test_dataset, batch_size_val, shuffle=True)\n",
        "#evaluate(model, eval_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1peenBhuW12y"
      },
      "source": [
        "#for b in eval_loader:\n",
        "#  print(b)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}